#!/usr/bin/env python

__license__   = 'GPL v3'
__copyright__ = '2011, Davide Cavalca <davide125 at tiscali.it>'
'''
lwn.net
'''

#-------------------------------------------------------------------------------
# Lukasz Janyst:
#
# Get a list of isses and select the one to download
# Print the issue release date on the cover - looks nice on the iPad
#-------------------------------------------------------------------------------


from calibre.web.feeds.news import BasicNewsRecipe
import re
import sys
import lxml
import os
from PythonMagick import *
from tempfile import mkstemp


class WeeklyLWN(BasicNewsRecipe):
    title = 'LWN.net Weekly Edition'
    description = 'Weekly summary of what has happened in the free software world.'
    __author__ = 'Davide Cavalca'
    language = 'en'
    site_url = u'http://lwn.net'
    timefmt = ''

    extra_css = 'pre,code,samp,kbd,tt { font-size: 80% }\nblockquote {margin-left:0 }\n* { color: black }\n'
    no_stylesheets = True
    remove_javascript = True

    publication_type = 'magazine'

    remove_tags_before = dict(attrs={'class':'PageHeadline'})
    remove_tags_after = dict(attrs={'class':'ArticleText'})
    remove_tags = [dict(name=['h2', 'form'])]

    preprocess_regexps = [
        # Remove the <hr> and "Log in to post comments"
        (re.compile(r'<hr [^>]+>\s*\n\s*.*?comments[)]'), lambda m: ''),
    ]

    conversion_options = {
        'linearize_tables' : True,
        'no_inline_navbars': True,
    }

    oldest_article = 7.0
    needs_subscription = 'optional'

    def get_cover_url(self):
        if self.cover_img is None:
            return None

        data = file( self.cover_img,'r').read()
        img  = Image( Blob(data) )
        img.fillColor( 'white' )
        img.boxColor( '#00000080' )
        img.density( '72x72' )
        img.fontPointsize(30)
        img.annotate( self.title[27:],
                      Geometry( 0, 0, 0, 15 ),
                      GravityType.SouthGravity,
                      0 );
        d = mkstemp('.png')[1]
        img.write( d )
        return d

    def get_issue_list(self):
        br = self.get_browser()
        doc = lxml.etree.parse( br.open('https://lwn.net/Archives/?n=100'),
                                lxml.etree.HTMLParser() )
        links  = doc.xpath( "//a")
        index  = 0
        issues = []
        for l in links:
            if not l.text:
                continue
            if not l.text.strip().startswith( 'LWN.net Weekly Edition for ' ):
                continue
            issues.append( (index, l.text, l.attrib['href'] + 'bigpage' ) )
            index += 1
        return issues

    def print_issue_list(self, issues):
        for issue in issues:
            print '[%d]: %s' % (issue[0], issue[1])

    def __init__(self, options, log, progress_reporter):
        BasicNewsRecipe.__init__(self, options, log, progress_reporter)
        issues = self.get_issue_list()
        if options.journal_list_issues:
            self.print_issue_list(issues)
            sys.exit(0)
        issueNum = int(options.journal_download_issue)
        if issueNum >= len(issues):
            print >>sys.stderr, 'No such issue:', issueNum
        self.cover_img = options.journal_cover
        self.issue_url = issues[issueNum][2]
        self.title     = issues[issueNum][1]

    def get_browser(self):
        br = BasicNewsRecipe.get_browser(self)
        if self.username is not None and self.password is not None:
            br.open('https://lwn.net/login')
            br.select_form(name='loginform')
            br['Username'] = self.username
            br['Password'] = self.password
            br.submit()
        return br

    def print_version(self, url):

        # Strip off anchor
        url = url.split('#')[0]

        # Prepend site_url
        if url[0:len(self.site_url)] != self.site_url:
            url = self.site_url + url

        # Append printable URL parameter
        print_param = '?format=printable'
        if url[-len(print_param):] != print_param:
            url += print_param

        return url

    def parse_index(self):
        index_url = self.print_version(self.issue_url)
        soup = self.index_to_soup(index_url)
        curr = soup.body

        articles = {}
        ans = []

        section = soup.title.string
        subsection = None

        while True:
            curr = curr.findNext(attrs={'class': ['SummaryHL', 'Cat1HL', 'Cat2HL']})

            if curr is None:
                break

            text = curr.contents[0].string

            if 'Cat2HL' in curr.attrMap['class']:
                subsection = text

            elif 'Cat1HL' in curr.attrMap['class']:
                section = text
                subsection = None

            elif 'SummaryHL' in curr.attrMap['class']:
                article_title = text

                if subsection:
                    section_title = "%s: %s" % (section, subsection)
                else:
                    section_title = section

                # Most articles have anchors in their titles, *except* the security vulnerabilities
                article_anchor = curr.findNext(name='a', attrs={'href': re.compile('^/Articles/')})

                if article_anchor:
                    article_url = article_anchor.get('href')
                    if not article_url:
                        print >>sys.stderr, 'article_url is None for article_anchor "%s": "%s"' \
                                % (str(article_anchor), article_title)
                        continue

                else:
                    print >>sys.stderr, 'article_anchor is None for "%s"; skipping' % article_title
                    article_url = None
                    continue

                if section_title not in articles:
                    articles[section_title] = []
                if section_title not in ans:
                    ans.append(section_title)

                articles[section_title].append({
                        'url': article_url,
                        'title': article_title,
                        'description': '', 'content': '', 'date': '',
                    })

            else:
                print >>sys.stderr, "lwn_weekly.recipe: something bad happened; should not be able to reach this"

        ans = [(section2, articles[section2]) for section2 in ans if section2 in articles]
        # from pprint import pprint
        # pprint(ans)

        return ans

# vim: expandtab:ts=4:sw=4

